#### 1. 学术术语

本小节主要探讨如何通过文献检索找到本研究合适的研究主题或方向。

<img width="794" alt="image" src="https://github.com/zaneCC/-/assets/8925869/bd1ba029-11a8-4fb9-973b-cfa0f435265f">


这个是百度百科给出的“类别不平衡”的解释，同时可以看到类别不平衡的英文名叫“Category imbalance”。

<img width="795" alt="image" src="https://github.com/zaneCC/-/assets/8925869/6158c0a4-c551-4254-9d91-387422d75e65">


我们通过知网学术翻译（比较推荐）查出类别不平衡其实不只有一个词，知网帮我们找到了5个翻译的词条。其中，“class imbalance”使用最为频繁。

本书根据知网学术翻译中得到的词条进行的文献检索，并根据现有中英文献整理出本书的主要内容。

#### 2. 评价指标

##### 2.1 数据评估指标

在高度不平衡的数据集中，标准的机器学习算法或深度学习算法可能难以学习正确地对少数类进行分类，从而导致在精度、召回率和其他评估指标方面表现不佳，且模型表现能力随数据集不平衡程度线性增加，研究这类问题需要一种公认的评估数据集不平衡程度方法。IR是评估数据集类别不平衡程度的指标，是不平衡数据集中少数类样本数与多数类样本数之比。假设正样本数量为$$N^+$$，负样本数量为$$N^-$$，则类别不平衡比率（Imbalance Ratio, IR）公式如（1)所示。

$$
IR=N^-/N^+
$$

##### 2.2 模型评价指标

当数据类别不平衡时，特别是极端类别不平衡情况下，传统的模型评价指标（如：准确度）可能不适用，因为它们可能会产生误导，并提供对模型性能的错误认识。常用的类别不平衡评价指标有：平衡准确度、精度、召回率、F1值和AUC。对于二分类问题，常用混淆矩阵将样本分为四类：真阳性（TP）、假阳性（FP）、真阴性（TN）、假阴性（FN），其混淆矩阵如**表2-1**所示。

​																				**表2-1 混淆矩阵**

|              | 预测结果为正 | 预测结果为负 |
| ------------ | ------------ | ------------ |
| 实际结果为正 | TP           | FN           |
| 实际结果为负 | FP           | TN           |

平衡准确度是在类别不平衡情况下替代准确度的指标，它被定义为数据集中所有类别的真阳性率（TPR）和真阴性率（TNR）的平均值，公式如（2）和（3）所示。其中TPR是正确预测的正例数除以正例总数，TNR是正确预测的负例数除以负例总数。平衡准确度的公式如（4）所示。

$$
TPR=TP/(TP+FN)
$$

$$
FPR=FP/(FP+TN)
$$

$$
Balanced Accuracy=(TPR+TNR)/2
$$

精度又称为精确度，针对于预测结果而言，表示预测结果为正的样本中实际正样本所占比例，其公式如（5）所示。根据精度公式可以看出，精度强调的是模型正确识别正样本的数量，因此不会受到样本不平衡的影响。但若模型仅将一个样本正确标记为正，其他样本都为负，根据精度公式，精度为1。造成这种问题的原因在于精度忽略了FN。

$$
Precision=TP/(TP+FP)
$$

召回率，针对于实际结果而言，表示实际为正的样本中模型成功预测得到正样本的比例，其公式如（6）所示。召回率与精度的公式很相似，相比于精度，召回率强调了精度所忽略的FN，而忽略了FP。

$$
Recall=TP/(TP+FN)
$$

精度和召回率各有其优点，F值则是将两者结合的指标，是精度和召回率的加权调和平均值，其中，F1值是$$\beta=1$$的情况，其公式如（7）所示。F值并不受样本类别平衡的影响，因此F值很适合作为不平衡数据下模型的评价指标。

$$
F_\beta=[(1+\beta^2)*precision*recall]/(\beta^2*precision+recall)
$$

AUC（ROC 曲线下的面积）是二元分类问题的机器学习模型中广泛使用的性能指标。AUC 衡量模型区分正类和负类的能力，并提供跨不同分类阈值的模型性能的聚合度量。AUC 提供了对模型性能的全面评估，因为它考虑了所有可能的分类阈值，这与需要特定阈值的准确性或精度等其他性能指标不同。此外，AUC 对类不平衡具有鲁棒性，这使得它在处理不平衡数据集时特别有用。

#### 3. 重采样方法

##### 过采样

##### 欠采样

##### 混合采样



#### 4. 损失函数方法



#### 5. 混合方法



#### 6. GAN生成数据

#### 
